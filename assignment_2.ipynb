{
<<<<<<< HEAD
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "notebook_metadata_filter": "-all",
      "text_representation": {
        "extension": ".py",
        "format_name": "light"
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
=======
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P94QId6spMdi"
   },
   "source": [
    "<img src=\"images/logo.png\" style=\"width: 100px;\"/>\n",
    "<h1><center>Assignment 2</center></h1>\n",
    "<h3><center>Decision Trees</center></h3>\n",
    "\n",
    "<center>Due: 09.11.2021 at 23:59</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mZyP9BspMdm"
   },
   "source": [
    "### How to upload:\n",
    "\n",
    "Upload your solution via the VC course. Please upload **one Zip archive** per group. The Zip must contain:\n",
    "* Your solution **notebook** (a **.ipynb** file)\n",
    "* An **images folder** with all your images (keep the size of the images relatively small)\n",
    "* A **data folder** with the datasets (you probably don't have to change anything here)\n",
    "\n",
    "Your Zip should be named after the following scheme:\n",
    "\n",
    "* assignment\\_\"**assignment number**\"\\_solution.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6aMSVIGh29_",
    "outputId": "bbe3cfa1-9a72-4325-e9e1-dd0b8b730d80"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_SZk-sAk60D",
    "outputId": "17ff7056-1bcf-4a8e-f404-5e08aaf2f45e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR-IljMdpMdn"
   },
   "source": [
    "# 1) Entropy\n",
    "\n",
    "Calculating the entropy is a thing that has to be done repeatedly when training a decision tree. Let's write a function for that. Our input is again the mushroom dataset, which we will first load into Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    "colab": {
      "name": "assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TV6MZJRDpMdr"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P94QId6spMdi"
      },
      "source": [
        "<img src=\"images/logo.png\" style=\"width: 100px;\"/>\n",
        "<h1><center>Assignment 2</center></h1>\n",
        "<h3><center>Decision Trees</center></h3>\n",
        "\n",
        "<center>Due: 09.11.2021 at 23:59</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mZyP9BspMdm"
      },
      "source": [
        "### How to upload:\n",
        "\n",
        "Upload your solution via the VC course. Please upload **one Zip archive** per group. The Zip must contain:\n",
        "* Your solution **notebook** (a **.ipynb** file)\n",
        "* An **images folder** with all your images (keep the size of the images relatively small)\n",
        "* A **data folder** with the datasets (you probably don't have to change anything here)\n",
        "\n",
        "Your Zip should be named after the following scheme:\n",
        "\n",
        "* assignment\\_\"**assignment number**\"\\_solution.zip"
      ]
    },
<<<<<<< HEAD
=======
    "id": "kBQKOMzlpMdo",
    "outputId": "3e637b1b-6cce-4f29-ddff-41e086c32d95",
    "scrolled": true
   },
   "outputs": [
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6aMSVIGh29_",
        "outputId": "bbe3cfa1-9a72-4325-e9e1-dd0b8b730d80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
<<<<<<< HEAD
    },
=======
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"data/UCI_mushroom_data.csv\", sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u20Yd9Q5pMdp"
   },
   "source": [
    "Now that we have the dataset loaded, let's write a function that will calculate us a multiclass entropy for a (subset of a) pandas dataframe. The input will be the dataframe and the column name of the target attribute. The function should figure out itself how many classes there are. For this you can have a look at the __df.unique()__ function of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GTY2KNgvpMdq"
   },
   "outputs": [
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_SZk-sAk60D",
        "outputId": "17ff7056-1bcf-4a8e-f404-5e08aaf2f45e"
      },
      "source": [
        "import glob\n",
        "print(glob.glob(\"/content/gdrive/My Drive/Colab Notebooks/chandrima/data/*\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/My Drive/Colab Notebooks/chandrima/data/UCI_mushroom_data.csv', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/test.csv', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/tree1.pickle', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/train.csv', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/tree2.pickle', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/breast_cancer.csv', '/content/gdrive/My Drive/Colab Notebooks/chandrima/data/UCI_mushroom_data_description.txt']\n"
          ]
        }
      ]
<<<<<<< HEAD
    },
=======
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiclass_entropy(data, target_attribute):\n",
    "    \n",
    "    #for figuring out how many classes there are\n",
    "    levels = data[target_attribute].unique()\n",
    "    \n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    \n",
    "    # for each value in the target attribute values\n",
    "    for level in levels:\n",
    "        # ratio of values occurring and entropy\n",
    "        fraction = data[target_attribute].value_counts()[level] / len(levels)\n",
    "        entropy += -fraction * np.log2(fraction)\n",
    "    return entropy\n",
    " \n",
    "multiclass_entropy(data, \"poisonous\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV6MZJRDpMdr"
   },
   "source": [
    "# 2) Information Gain \n",
    "\n",
    "Create a function that given a dataset, an attribute name and a target column name, calculates the information gain for the given attribute:\n",
    "\n",
    "The Method should work with the following call:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dbPrqdMpMdr",
    "lines_to_next_cell": 2
   },
   "source": [
    "Method-Call: information_gain(data=data, attribute=\"odor\", target_attribute=\"poisonous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v4MtKK3spMds"
   },
   "outputs": [
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR-IljMdpMdn"
      },
      "source": [
        "# 1) Entropy\n",
        "\n",
        "Calculating the entropy is a thing that has to be done repeatedly when training a decision tree. Let's write a function for that. Our input is again the mushroom dataset, which we will first load into Pandas:"
      ]
<<<<<<< HEAD
    },
=======
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def information_gain(data, attribute, target_attribute):  \n",
    "    \n",
    "    # Calculate the original entropy\n",
    "    original_entropy = multiclass_entropy(data, target_attribute)\n",
    "    # print(original_entropy)\n",
    "\n",
    "    #Type of values of attribute\n",
    "    values = data[attribute].unique()\n",
    "    #print(multiclass_entropy(data, attribute))\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[attribute],return_counts=True)\n",
    "    #print(vals,counts)\n",
    "    \n",
    "    for i in range(len(vals)):\n",
    "        #Calculate the weighted entropy\n",
    "        Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*multiclass_entropy(data,attribute) ])\n",
    "    \n",
    "        #Calculate the information gain\n",
    "        Information_Gain = original_entropy - Weighted_Entropy\n",
    "    return Information_Gain    \n",
    "\n",
    "\n",
    "\n",
    "information_gain(data, \"bruises\", \"poisonous\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BCrVDILpMdt"
   },
   "source": [
    "What column has the **highest information gain**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_PtxmqhIpMdu"
   },
   "outputs": [
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kBQKOMzlpMdo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "3e637b1b-6cce-4f29-ddff-41e086c32d95"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"data/UCI_mushroom_data.csv\", sep=\",\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5c3d4aded727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/UCI_mushroom_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/UCI_mushroom_data.csv'"
          ]
        }
      ]
<<<<<<< HEAD
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u20Yd9Q5pMdp"
      },
      "source": [
        "Now that we have the dataset loaded, let's write a function that will calculate us a multiclass entropy for a (subset of a) pandas dataframe. The input will be the dataframe and the column name of the target attribute. The function should figure out itself how many classes there are. For this you can have a look at the __df.unique()__ function of Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTY2KNgvpMdq"
      },
      "source": [
        "def multiclass_entropy(data, target_attribute):\n",
        "    \n",
        "    #for figuring out how many classes there are\n",
        "    levels = data[target_attribute].unique()\n",
        "    \n",
        "    # Initialize the entropy to 0\n",
        "    entropy = 0\n",
        "    \n",
        "    # for each value in the target attribute values\n",
        "    for level in levels:\n",
        "        # ratio of values occurring and entropy\n",
        "        fraction = data[target_attribute].value_counts()[level] / len(levels)\n",
        "        entropy += -fraction * np.log2(fraction)\n",
        "    return entropy\n",
        " \n",
        "multiclass_entropy(data, \"poisonous\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV6MZJRDpMdr"
      },
      "source": [
        "# 2) Information Gain \n",
        "\n",
        "Create a function that given a dataset, an attribute name and a target column name, calculates the information gain for the given attribute:\n",
        "\n",
        "The Method should work with the following call:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "8dbPrqdMpMdr"
      },
      "source": [
        "Method-Call: information_gain(data=data, attribute=\"odor\", target_attribute=\"poisonous\")"
      ]
    },
=======
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(np.array(data.keys())[1:])\n",
    "def highest_info_gain(columns):\n",
    "\n",
    "    # Intialize an empty dictionary for information gains\n",
    "\n",
    "    information_gains = {}\n",
    "    \n",
    "\n",
    "    # Iterate through each column name in our list\n",
    "\n",
    "    for col in columns:\n",
    "\n",
    "        # Find the information gain for the column\n",
    "\n",
    "        IG = information_gain(data, col, 'poisonous')\n",
    "        # Add the information gain to our dictionary using the column name as the ekey\n",
    "\n",
    "        information_gains[col] = IG\n",
    "\n",
    "    # Return the key with the highest value\n",
    "    return max(information_gains) , information_gains[max(information_gains)]\n",
    "\n",
    "\n",
    "highest_info_gain(np.array(data.keys())[1:])                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFOzbLbjpMdu"
   },
   "source": [
    "# 3) Evaluate a decision tree\n",
    "\n",
    "In this task you will use different decision trees to classify data.\n",
    "Therefore we first need two classes that represent a single node and a single edge of a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HP6219ORpMdv"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    value: The name of the decision attribute. If this is a leaf node, 'value' is the prediction value\n",
    "    edges: A list of edge objects\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.value = \"\"\n",
    "        self.edges = []\n",
    "\n",
    "class Edge:\n",
    "    \"\"\"\n",
    "    label: An attribute value.\n",
    "    node: The subsequent node that is hanging at this edge.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.label = \"\"\n",
    "        self.node = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr1EsEF3pMdv"
   },
   "source": [
    "The __Node__ class has a property for the __value__ (either an attribute or a class for the leaf nodes) and a property for the list of outgoing __edges__. This list should be filled with objects of the class __Edge__.\n",
    "\n",
    "The __Edge__ class has a property for the __label__ of the edge as well as a property for the attached __node__ that comes at the next layer.\n",
    "\n",
    "Since we also want to show our decision tree, we also give you functions to print your tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0G-vAx5DpMdv"
   },
   "outputs": [],
   "source": [
    "def print_tree(root):\n",
    "    print(print_tree_at_layer(root, 0))\n",
    "\n",
    "def print_tree_at_layer(tree, layer):\n",
    "    text = str(tree.value)\n",
    "    text += \"\\n\"\n",
    "    if not len(tree.edges) == 0:\n",
    "        for e in tree.edges:\n",
    "            text += \"\\t\" * (layer+1)\n",
    "            text += f\"{e.label}: {print_tree_at_layer(e.node, layer + 1)}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8qOdoCGpMdw"
   },
   "source": [
    "The function __print_tree(root)__ takes the root node (an object of class __Node__) of the tree and prints it in a typical 'console directory printing style' where each line contains one node (with a possible edge label prefix). The indentation gives an indication at which layer we currently are. __print_tree_at_layer__ is an auxiliary function.\n",
    "\n",
    "Your task is now to write a function `inference` that takes an instance and classifies it with a given decision tree. We give you a simple example of a decision tree so that you can test you function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REwLB8tKpMdw",
    "outputId": "e5fdb55d-1551-422f-fdbd-c9fe37eba396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "\tb: B\n",
      "\t\td: D\n",
      "\t\te: E\n",
      "\tc: C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example tree\n",
    "tree = Node()\n",
    "tree.value = \"A\"\n",
    "tree_B = Node()\n",
    "tree_B.value = \"B\"\n",
    "tree_C = Node()\n",
    "tree_C.value = \"C\"\n",
    "tree_D = Node()\n",
    "tree_D.value = \"D\"\n",
    "tree_E = Node()\n",
    "tree_E.value = \"E\"\n",
    "\n",
    "edge_to_B = Edge()\n",
    "edge_to_B.label = \"b\"\n",
    "edge_to_B.node = tree_B\n",
    "\n",
    "edge_to_C = Edge()\n",
    "edge_to_C.label = \"c\"\n",
    "edge_to_C.node = tree_C\n",
    "\n",
    "edge_to_D = Edge()\n",
    "edge_to_D.label = \"d\"\n",
    "edge_to_D.node = tree_D\n",
    "\n",
    "edge_to_E = Edge()\n",
    "edge_to_E.label = \"e\"\n",
    "edge_to_E.node = tree_E\n",
    "\n",
    "tree.edges = [edge_to_B, edge_to_C]\n",
    "tree_B.edges = [edge_to_D, edge_to_E]\n",
    "\n",
    "# print(tree)\n",
    "print_tree(tree)\n",
    "\n",
    "def inference(example, tree, attributes):\n",
    "    \"\"\"\n",
    "    example: Single instance to be classified, in the form of an array containing the attribute values\n",
    "    tree: The root node of a decision tree, built with the classes Node and Edge from above\n",
    "    attributes: An index array that contains the attribute names in the order in which the attributes appear in example\n",
    "    \"\"\"\n",
    "    currentNode = tree\n",
    "    while(currentNode):\n",
    "        if len(currentNode.edges) == 0:\n",
    "          return currentNode.value;\n",
    "        edge_label = example[attributes.index(currentNode.value)]\n",
    "        # print(edge_label)\n",
    "        for edge in currentNode.edges:\n",
    "          if edge.label == edge_label:\n",
    "            currentNode=edge.node\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmJeAuyvpMdx",
    "outputId": "f2d75942-5d7b-460f-e9bf-6dc99457abf5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n"
     ]
    }
   ],
   "source": [
    "# Use this as a test - write more tests if you want\n",
    "'E' == inference([\"b\", \"e\"], tree, [\"A\", \"B\"])\n",
    "# 'B' == inference([\"b\"], tree, [\"A\"])\n",
    "# print(inference([\"b\", \"e\"], tree, [\"A\", \"B\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdfjK90ZpMdx"
   },
   "source": [
    "In the next task, we want you to **use the inference-function to evaluate how well pre-trained decision trees perform on test data**.    \n",
    "Here is some background information on how we obtained the decision trees: We chose a data set from the UCI-libraries (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer) denoting whether a person had a recurring case of breast cancer, along with other medical information. We split the data into a training and a test set. We applied two different (unknown to you ;) ) adaptations of the ID3-algorithm to train two decision trees on the train set. Here are the datasets we used and the trees (`tree1`, `tree2`) we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xbr5mWwopMdx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/tree1.pickle', 'rb') as file:\n",
    "    tree1 = pickle.load(file) \n",
    "    \n",
    "with open('data/tree2.pickle', 'rb') as file:\n",
    "    tree2 = pickle.load(file)\n",
    "    \n",
    "training_df = pd.read_csv('data/train.csv', dtype=object)\n",
    "test_df = pd.read_csv('data/test.csv', dtype=object)\n",
    "\n",
    "\n",
    "attributes = np.array(test_df.keys())[1:].tolist()\n",
    "\n",
    "tree1_test_prediction = []\n",
    "tree2_test_prediction = []\n",
    "for row in np.array(test_df):\n",
    "  x=inference(row[1:].tolist(), tree1, attributes)\n",
    "  tree1_test_prediction.append(x)\n",
    "  x=inference(row[1:].tolist(), tree2, attributes)\n",
    "  tree2_test_prediction.append(x)  \n",
    "tree1_test_prediction = np.array(tree1_test_prediction)\n",
    "tree2_test_prediction = np.array(tree2_test_prediction)\n",
    "test_classes=np.array(test_df)[:,0:1].reshape((1,test_df.shape[0]))[0];\n",
    "# tree1_error=train_result.shape[0]-(tree1_inference==train_result).sum()\n",
    "# tree2_error=train_result.shape[0]-(tree2_test_inference==train_result).sum()\n",
    "\n",
    "\n",
    "tree1_train_prediction = []\n",
    "tree2_train_prediction = []\n",
    "for row in np.array(training_df):\n",
    "  x=inference(row[1:].tolist(), tree1, attributes)\n",
    "  tree1_train_prediction.append(x)\n",
    "  x=inference(row[1:].tolist(), tree2, attributes)\n",
    "  tree2_train_prediction.append(x)\n",
    "tree1_train_prediction = np.array(tree1_train_prediction)\n",
    "tree2_train_prediction = np.array(tree2_train_prediction)\n",
    "train_classes=np.array(training_df)[:,0:1].reshape((1,training_df.shape[0]))[0];\n",
    "# tree1_error=train_result.shape[0]-(tree1_inference==train_result).sum()\n",
    "# tree2_error=train_result.shape[0]-(tree2_inference==train_result).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4a2SX9jARHX",
    "outputId": "03ad69ed-700f-4c29-e66c-863fb5e47a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv-nodes\n",
      "\t0-2: tumor-size\n",
      "\t\t30-34: 0\n",
      "\t\t20-24: 0\n",
      "\t\t15-19: 0\n",
      "\t\t0-4: 0\n",
      "\t\t25-29: 0\n",
      "\t\t50-54: 0\n",
      "\t\t10-14: 0\n",
      "\t\t40-44: 0\n",
      "\t\t35-39: 0\n",
      "\t\t5-9: 0\n",
      "\t\t45-49: 1\n",
      "\t6-8: deg-malig\n",
      "\t\t3: 1\n",
      "\t\t2: 0\n",
      "\t\t1: 1\n",
      "\t9-11: age\n",
      "\t\t30-39: 1\n",
      "\t\t40-49: 0\n",
      "\t\t60-69: 1\n",
      "\t\t50-59: 0\n",
      "\t\t70-79: 1\n",
      "\t\t20-29: 1\n",
      "\t3-5: deg-malig\n",
      "\t\t3: 1\n",
      "\t\t2: 0\n",
      "\t\t1: 0\n",
      "\t15-17: menopause\n",
      "\t\tpremeno: 1\n",
      "\t\tge40: 0\n",
      "\t\tlt40: 0\n",
      "\t12-14: tumor-size\n",
      "\t\t30-34: 1\n",
      "\t\t20-24: 0\n",
      "\t\t15-19: 0\n",
      "\t\t0-4: 0\n",
      "\t\t25-29: 0\n",
      "\t\t50-54: 0\n",
      "\t\t10-14: 0\n",
      "\t\t40-44: 0\n",
      "\t\t35-39: 0\n",
      "\t\t5-9: 0\n",
      "\t\t45-49: 0\n",
      "\t24-26: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print_tree(tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hpqq5E_gpMdy"
   },
   "source": [
    "Now use your inference function from above to check if the trees predict correctly. **To do this calculate the accuracy of the predictions of the target attribute on both the training-set and the test-set for both trees.**\n",
    "\n",
    "*In the dataset the attribute `Class` denotes the target attribute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IK_TQdx8pMdy",
    "outputId": "d467c9c3-00a8-48db-8495-41d34b9399e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6744186046511628\n",
      "0.7674418604651163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tree1_accuracy = accuracy_score(test_classes, tree1_test_prediction)\n",
    "tree2_accuracy = accuracy_score(test_classes, tree2_test_prediction)\n",
    "print(tree1_accuracy)\n",
    "print(tree2_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm8vAh1HpMdy"
   },
   "source": [
    "**Questions:**\n",
    "(1) Looking at these accuracies, would you rather use tree1 or tree2 in a real world scenario to predict whether a person might have recurring breast cancer? Explain your choice and explicitly explain why you did **not** choose a certain tree. Try to come up with an explanation for the accuracy values of the two trees.   \n",
    "(2) What do you think were the adaptations we used when training the two trees?\n",
    "\n",
    "*Hint: You can also print both trees with the function print_tree(root) and compare the output for additional information*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpuHDFzApMdy"
   },
   "source": [
    "*Your solution here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9LWdzP2sAzX"
   },
   "source": [
    "Answer:(1)\n",
    "\n",
    "From the result it seems `tree2` gives higher accuracy `tree1`. But from the visualisation of `tree2` shows that, decision depends only on inv-nodes and one other attribute. That's why it's showing high accuracy.\n",
    "\n",
    "So in real world scenario, `tree1` will show better usability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRYL4jRqpMdz"
   },
   "source": [
    "---\n",
    "# Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RS_To0UpMdz"
   },
   "source": [
    "\n",
    "### 1) Embedding images\n",
    "You can embed images in a jupyter notebook on two ways: <br/>\n",
    "First, you can use the IPython kernel to draw an image everytime the code cell is run like shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0xbc8HOwpMdz"
   },
   "outputs": [
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4MtKK3spMds"
      },
      "source": [
        "def information_gain(data, attribute, target_attribute):  \n",
        "    \n",
        "    # Calculate the original entropy\n",
        "    original_entropy = multiclass_entropy(data, target_attribute)\n",
        "    # print(original_entropy)\n",
        "\n",
        "    #Type of values of attribute\n",
        "    values = data[attribute].unique()\n",
        "    #print(multiclass_entropy(data, attribute))\n",
        "    \n",
        "    #Calculate the values and the corresponding counts for the split attribute \n",
        "    vals,counts= np.unique(data[attribute],return_counts=True)\n",
        "    #print(vals,counts)\n",
        "    \n",
        "    for i in range(len(vals)):\n",
        "        #Calculate the weighted entropy\n",
        "        Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*multiclass_entropy(data,attribute) ])\n",
        "    \n",
        "        #Calculate the information gain\n",
        "        Information_Gain = original_entropy - Weighted_Entropy\n",
        "    return Information_Gain    \n",
        "\n",
        "\n",
        "\n",
        "information_gain(data, \"bruises\", \"poisonous\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BCrVDILpMdt"
      },
      "source": [
        "What column has the **highest information gain**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PtxmqhIpMdu"
      },
      "source": [
        "#print(np.array(data.keys())[1:])\n",
        "def highest_info_gain(columns):\n",
        "\n",
        "    # Intialize an empty dictionary for information gains\n",
        "\n",
        "    information_gains = {}\n",
        "    \n",
        "\n",
        "    # Iterate through each column name in our list\n",
        "\n",
        "    for col in columns:\n",
        "\n",
        "        # Find the information gain for the column\n",
        "\n",
        "        IG = information_gain(data, col, 'poisonous')\n",
        "        # Add the information gain to our dictionary using the column name as the ekey\n",
        "\n",
        "        information_gains[col] = IG\n",
        "\n",
        "    # Return the key with the highest value\n",
        "    return max(information_gains) , information_gains[max(information_gains)]\n",
        "\n",
        "\n",
        "highest_info_gain(np.array(data.keys())[1:])                                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFOzbLbjpMdu"
      },
      "source": [
        "# 3) Evaluate a decision tree\n",
        "\n",
        "In this task you will use different decision trees to classify data.\n",
        "Therefore we first need two classes that represent a single node and a single edge of a decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP6219ORpMdv"
      },
      "source": [
        "class Node:\n",
        "    \"\"\"\n",
        "    value: The name of the decision attribute. If this is a leaf node, 'value' is the prediction value\n",
        "    edges: A list of edge objects\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.value = \"\"\n",
        "        self.edges = []\n",
        "\n",
        "class Edge:\n",
        "    \"\"\"\n",
        "    label: An attribute value.\n",
        "    node: The subsequent node that is hanging at this edge.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.label = \"\"\n",
        "        self.node = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr1EsEF3pMdv"
      },
      "source": [
        "The __Node__ class has a property for the __value__ (either an attribute or a class for the leaf nodes) and a property for the list of outgoing __edges__. This list should be filled with objects of the class __Edge__.\n",
        "\n",
        "The __Edge__ class has a property for the __label__ of the edge as well as a property for the attached __node__ that comes at the next layer.\n",
        "\n",
        "Since we also want to show our decision tree, we also give you functions to print your tree:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G-vAx5DpMdv"
      },
      "source": [
        "def print_tree(root):\n",
        "    print(print_tree_at_layer(root, 0))\n",
        "\n",
        "def print_tree_at_layer(tree, layer):\n",
        "    text = str(tree.value)\n",
        "    text += \"\\n\"\n",
        "    if not len(tree.edges) == 0:\n",
        "        for e in tree.edges:\n",
        "            text += \"\\t\" * (layer+1)\n",
        "            text += f\"{e.label}: {print_tree_at_layer(e.node, layer + 1)}\"\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8qOdoCGpMdw"
      },
      "source": [
        "The function __print_tree(root)__ takes the root node (an object of class __Node__) of the tree and prints it in a typical 'console directory printing style' where each line contains one node (with a possible edge label prefix). The indentation gives an indication at which layer we currently are. __print_tree_at_layer__ is an auxiliary function.\n",
        "\n",
        "Your task is now to write a function `inference` that takes an instance and classifies it with a given decision tree. We give you a simple example of a decision tree so that you can test you function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REwLB8tKpMdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e5fdb55d-1551-422f-fdbd-c9fe37eba396"
      },
      "source": [
        "# example tree\n",
        "tree = Node()\n",
        "tree.value = \"A\"\n",
        "tree_B = Node()\n",
        "tree_B.value = \"B\"\n",
        "tree_C = Node()\n",
        "tree_C.value = \"C\"\n",
        "tree_D = Node()\n",
        "tree_D.value = \"D\"\n",
        "tree_E = Node()\n",
        "tree_E.value = \"E\"\n",
        "\n",
        "edge_to_B = Edge()\n",
        "edge_to_B.label = \"b\"\n",
        "edge_to_B.node = tree_B\n",
        "\n",
        "edge_to_C = Edge()\n",
        "edge_to_C.label = \"c\"\n",
        "edge_to_C.node = tree_C\n",
        "\n",
        "edge_to_D = Edge()\n",
        "edge_to_D.label = \"d\"\n",
        "edge_to_D.node = tree_D\n",
        "\n",
        "edge_to_E = Edge()\n",
        "edge_to_E.label = \"e\"\n",
        "edge_to_E.node = tree_E\n",
        "\n",
        "tree.edges = [edge_to_B, edge_to_C]\n",
        "tree_B.edges = [edge_to_D, edge_to_E]\n",
        "\n",
        "# print(tree)\n",
        "print_tree(tree)\n",
        "\n",
        "def inference(example, tree, attributes):\n",
        "    \"\"\"\n",
        "    example: Single instance to be classified, in the form of an array containing the attribute values\n",
        "    tree: The root node of a decision tree, built with the classes Node and Edge from above\n",
        "    attributes: An index array that contains the attribute names in the order in which the attributes appear in example\n",
        "    \"\"\"\n",
        "    currentNode = tree\n",
        "    while(currentNode):\n",
        "        if len(currentNode.edges) == 0:\n",
        "          return currentNode.value;\n",
        "        edge_label = example[attributes.index(currentNode.value)]\n",
        "        # print(edge_label)\n",
        "        for edge in currentNode.edges:\n",
        "          if edge.label == edge_label:\n",
        "            currentNode=edge.node\n",
        "            break;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "\tb: B\n",
            "\t\td: D\n",
            "\t\te: E\n",
            "\tc: C\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cmJeAuyvpMdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d75942-5d7b-460f-e9bf-6dc99457abf5"
      },
      "source": [
        "# Use this as a test - write more tests if you want\n",
        "# 'E' == inference([\"b\", \"e\"], tree, [\"A\", \"B\"])\n",
        "# 'B' == inference([\"b\"], tree, [\"A\"])\n",
        "print(inference([\"b\", \"e\"], tree, [\"A\", \"B\"]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdfjK90ZpMdx"
      },
      "source": [
        "In the next task, we want you to **use the inference-function to evaluate how well pre-trained decision trees perform on test data**.    \n",
        "Here is some background information on how we obtained the decision trees: We chose a data set from the UCI-libraries (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer) denoting whether a person had a recurring case of breast cancer, along with other medical information. We split the data into a training and a test set. We applied two different (unknown to you ;) ) adaptations of the ID3-algorithm to train two decision trees on the train set. Here are the datasets we used and the trees (`tree1`, `tree2`) we generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbr5mWwopMdx"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/chandrima/data/tree1.pickle', 'rb') as file:\n",
        "    tree1 = pickle.load(file) \n",
        "    \n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/chandrima/data/tree2.pickle', 'rb') as file:\n",
        "    tree2 = pickle.load(file)\n",
        "    \n",
        "training_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/chandrima/data/train.csv', dtype=object)\n",
        "test_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/chandrima/data/test.csv', dtype=object)\n",
        "\n",
        "\n",
        "attributes = np.array(test_df.keys())[1:].tolist()\n",
        "\n",
        "tree1_test_prediction = []\n",
        "tree2_test_prediction = []\n",
        "for row in np.array(test_df):\n",
        "  x=inference(row[1:].tolist(), tree1, attributes)\n",
        "  tree1_test_prediction.append(x)\n",
        "  x=inference(row[1:].tolist(), tree2, attributes)\n",
        "  tree2_test_prediction.append(x)  \n",
        "tree1_test_prediction = np.array(tree1_test_prediction)\n",
        "tree2_test_prediction = np.array(tree2_test_prediction)\n",
        "test_classes=np.array(test_df)[:,0:1].reshape((1,test_df.shape[0]))[0];\n",
        "# tree1_error=train_result.shape[0]-(tree1_inference==train_result).sum()\n",
        "# tree2_error=train_result.shape[0]-(tree2_test_inference==train_result).sum()\n",
        "\n",
        "\n",
        "tree1_train_prediction = []\n",
        "tree2_train_prediction = []\n",
        "for row in np.array(training_df):\n",
        "  x=inference(row[1:].tolist(), tree1, attributes)\n",
        "  tree1_train_prediction.append(x)\n",
        "  x=inference(row[1:].tolist(), tree2, attributes)\n",
        "  tree2_train_prediction.append(x)\n",
        "tree1_train_prediction = np.array(tree1_train_prediction)\n",
        "tree2_train_prediction = np.array(tree2_train_prediction)\n",
        "train_classes=np.array(training_df)[:,0:1].reshape((1,training_df.shape[0]))[0];\n",
        "# tree1_error=train_result.shape[0]-(tree1_inference==train_result).sum()\n",
        "# tree2_error=train_result.shape[0]-(tree2_inference==train_result).sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4a2SX9jARHX",
        "outputId": "03ad69ed-700f-4c29-e66c-863fb5e47a7d"
      },
      "source": [
        "print_tree(tree2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inv-nodes\n",
            "\t0-2: tumor-size\n",
            "\t\t30-34: 0\n",
            "\t\t20-24: 0\n",
            "\t\t15-19: 0\n",
            "\t\t0-4: 0\n",
            "\t\t25-29: 0\n",
            "\t\t50-54: 0\n",
            "\t\t10-14: 0\n",
            "\t\t40-44: 0\n",
            "\t\t35-39: 0\n",
            "\t\t5-9: 0\n",
            "\t\t45-49: 1\n",
            "\t6-8: deg-malig\n",
            "\t\t3: 1\n",
            "\t\t2: 0\n",
            "\t\t1: 1\n",
            "\t9-11: age\n",
            "\t\t30-39: 1\n",
            "\t\t40-49: 0\n",
            "\t\t60-69: 1\n",
            "\t\t50-59: 0\n",
            "\t\t70-79: 1\n",
            "\t\t20-29: 1\n",
            "\t3-5: deg-malig\n",
            "\t\t3: 1\n",
            "\t\t2: 0\n",
            "\t\t1: 0\n",
            "\t15-17: menopause\n",
            "\t\tpremeno: 1\n",
            "\t\tge40: 0\n",
            "\t\tlt40: 0\n",
            "\t12-14: tumor-size\n",
            "\t\t30-34: 1\n",
            "\t\t20-24: 0\n",
            "\t\t15-19: 0\n",
            "\t\t0-4: 0\n",
            "\t\t25-29: 0\n",
            "\t\t50-54: 0\n",
            "\t\t10-14: 0\n",
            "\t\t40-44: 0\n",
            "\t\t35-39: 0\n",
            "\t\t5-9: 0\n",
            "\t\t45-49: 0\n",
            "\t24-26: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpqq5E_gpMdy"
      },
      "source": [
        "Now use your inference function from above to check if the trees predict correctly. **To do this calculate the accuracy of the predictions of the target attribute on both the training-set and the test-set for both trees.**\n",
        "\n",
        "*In the dataset the attribute `Class` denotes the target attribute.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK_TQdx8pMdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d467c9c3-00a8-48db-8495-41d34b9399e7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "tree1_accuracy = accuracy_score(test_classes, tree1_test_prediction)\n",
        "tree2_accuracy = accuracy_score(test_classes, tree2_test_prediction)\n",
        "print(tree1_accuracy)\n",
        "print(tree2_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6744186046511628\n",
            "0.7674418604651163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm8vAh1HpMdy"
      },
      "source": [
        "**Questions:**\n",
        "(1) Looking at these accuracies, would you rather use tree1 or tree2 in a real world scenario to predict whether a person might have recurring breast cancer? Explain your choice and explicitly explain why you did **not** choose a certain tree. Try to come up with an explanation for the accuracy values of the two trees.   \n",
        "(2) What do you think were the adaptations we used when training the two trees?\n",
        "\n",
        "*Hint: You can also print both trees with the function print_tree(root) and compare the output for additional information*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpuHDFzApMdy"
      },
      "source": [
        "*Your solution here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9LWdzP2sAzX"
      },
      "source": [
        "Answer:(1)\n",
        "\n",
        "From the result it seems `tree2` gives higher accuracy `tree1`. But from the visualisation of `tree2` shows that, decision depends only on inv-nodes and one other attribute. That's why it's showing high accuracy.\n",
        "\n",
        "So in real world scenario, `tree1` will show better usability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRYL4jRqpMdz"
      },
      "source": [
        "---\n",
        "# Tips and tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RS_To0UpMdz"
      },
      "source": [
        "\n",
        "### 1) Embedding images\n",
        "You can embed images in a jupyter notebook on two ways: <br/>\n",
        "First, you can use the IPython kernel to draw an image everytime the code cell is run like shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xbc8HOwpMdz"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"images/logo.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wrCk5YpMdz"
      },
      "source": [
        "Second, you can embed images directly in a Markdown cell as shown below. You can either use markdown syntax or write plain HTML code. Sometimes HTML code is more practical, as you have much finer control over the HTML elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8r10NKNpMdz"
      },
      "source": [
        "1. Markdown syntax:\n",
        "![title](images/logo.png)\n",
        "2. HTML syntax\n",
        "<img src=\"images/logo.png\" style=\"width: 70px;\"/>"
      ]
<<<<<<< HEAD
    }
  ]
}
=======
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9wrCk5YpMdz"
   },
   "source": [
    "Second, you can embed images directly in a Markdown cell as shown below. You can either use markdown syntax or write plain HTML code. Sometimes HTML code is more practical, as you have much finer control over the HTML elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8r10NKNpMdz"
   },
   "source": [
    "1. Markdown syntax:\n",
    "![title](images/logo.png)\n",
    "2. HTML syntax\n",
    "<img src=\"images/logo.png\" style=\"width: 70px;\"/>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TV6MZJRDpMdr"
   ],
   "name": "assignment_2.ipynb",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
>>>>>>> e5857f3c7761f53c1e8cb84fab05bb54e9b45c70
