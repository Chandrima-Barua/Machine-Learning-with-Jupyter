{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo.png\" style=\"width: 100px;\"/>\n",
    "<h1><center>Assignment 1</center></h1>\n",
    "<h3><center>Basic Concepts of Machine Learning and Foundations of Concept Learning</h3></center>\n",
    "\n",
    "<center>Due: 02.11.2021 at 23:59</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1) Hypothesis Testing\n",
    "\n",
    "<br>\n",
    "Consider the mushroom dataset at \"data/UCI_mushroom_data.csv\". There are a lot of free datasets available at the UCI repository for machine learning practitioners to develop new machine learning approaches.<br>\n",
    "The mushroom dataset contains information about different kinds of mushrooms.<br> <br>\n",
    "There is a description about the different attributes and the dataset's origin in the \"data/UCI_mushroom_data_description.txt\" file. <br>\n",
    "\n",
    "<br> <br>\n",
    "The first column of the dataset contains the class labels: <br>\n",
    "\n",
    "- **1** denotes a poisonous mushroom\n",
    "- **0** denotes an eatable mushroom\n",
    "\n",
    "There are **2156** poisonous and **3488** eatable mushrooms in the dataset.\n",
    "<br><br>\n",
    "First implement a function **is_more_general** which takes two hypotheses and checks whether the first hypothesis is more general than the second one. An example hypothesis to **detect poisonous mushrooms** is given below.\n",
    "<br><br>\n",
    "Your next task is to implemnt the FIND-S algorithm on the mushroom dataset to find a maximally specific hypothesis which is consistent with the mushroom dataset to **detect poisonous mushrooms**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, first start by loading and inspecting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poisonous</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   poisonous cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0          1         x           s         n       t    p               f   \n",
       "1          0         x           s         y       t    a               f   \n",
       "2          0         b           s         w       t    l               f   \n",
       "3          1         x           y         w       t    p               f   \n",
       "4          0         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "data = pd.read_csv(\"data/UCI_mushroom_data.csv\", sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypotheses should be in the form of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = ['?','?','?','?','f','f','c','b','?','e','?','?','?','?','?','p','?','?','?','h','v','?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the funtion **is_more_general**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is_more_general should take two hypotheses and check\n",
    "# whether the first of them is more general than the second.\n",
    "# If the first is more general it should return True, otherwise False.\n",
    "# Be aware: Sometimes one can not order hypotheses in a \"more general than\" relation.\n",
    "# In this case the function should also return False.\n",
    "\n",
    "def is_more_general(first_hypothesis, second_hypothesis): # given\n",
    "    # TODO\n",
    "    if len(first_hypothesis) == len(second_hypothesis):\n",
    "        eq_counter = 0\n",
    "        if first_hypothesis == second_hypothesis:\n",
    "            return False\n",
    "        for i in range(len(first_hypothesis)):\n",
    "            if (first_hypothesis[i] != '?') & (second_hypothesis[i] == '?'):\n",
    "                return False\n",
    "            elif (first_hypothesis[i] != '?') & (second_hypothesis[i] != '?'):\n",
    "                eq_counter = eq_counter+1\n",
    "            elif first_hypothesis[i] == second_hypothesis[i]:\n",
    "                eq_counter = eq_counter+1\n",
    "        if eq_counter == len(first_hypothesis):\n",
    "            return False\n",
    "        return True\n",
    "    else: \n",
    "        print(\"The hypotheses do not match in length\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Example test cases (you can define your own as well, there are more possibilities!)\n",
    "\n",
    "hypothesis1 = ['?','?','?','f','?','f','?','b','?','e','b','?','?','?','?','p','?','?','?','h','v','?']\n",
    "hypothesis2 = ['?','?','?','f','f','?','c','b','?','e','?','?','?','?','?','?','?','?','?','h','v','?']\n",
    "\n",
    "\n",
    "#print(is_more_general(hypothesis1, hypothesis2))\n",
    "\n",
    "# better check\n",
    "#equal = False\n",
    "hypothesis1 = ['?','?','?','?','warm','?'] \n",
    "hypothesis2 = ['?','?','?','?','warm','?']\n",
    "print(False == is_more_general(hypothesis1, hypothesis2))\n",
    " \n",
    "#first is more general = True\n",
    " \n",
    "hypothesis3 = ['?','?','?','?','warm','?'] \n",
    "hypothesis4 = ['?','?','?','?','warm','same']\n",
    "print(True == is_more_general(hypothesis3, hypothesis4))\n",
    " \n",
    "#second is more general = False\n",
    " \n",
    "hypothesis5 = ['?','?','?','?','warm','?'] \n",
    "hypothesis6 = ['?','?','?','?','?','?']\n",
    "print(False == is_more_general(hypothesis5, hypothesis6))\n",
    " \n",
    "#can't compare = False\n",
    "hypothesis7 = ['?','?','?','?','warm','?'] \n",
    "hypothesis8 = ['?','?','?','strong','?','same'] \n",
    "print(False == is_more_general(hypothesis7, hypothesis8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the FIND-S algorithm presented in the lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_s(attributes, target): # given\n",
    "    #most specific hypothesis\n",
    "    hypothesis = [None]*len(attributes[0])\n",
    "    #iterate through examples\n",
    "    for i in range(0, len(attributes)):\n",
    "        #only consider positive examples\n",
    "        if target[i]==1:\n",
    "            example_attributes = attributes[i]\n",
    "            #iterate trough attributes of current example\n",
    "            for j in range(0, len(example_attributes)):\n",
    "                #if the hypothesis indicates None for the current attribute, replace it with current value\n",
    "                if hypothesis[j] == None:\n",
    "                    hypothesis[j] = example_attributes[j]\n",
    "                #if hypothesis value and current attribute value do not match, replace it with ?\n",
    "                elif hypothesis[j] != example_attributes[j]:\n",
    "                    hypothesis[j] = \"?\"\n",
    "            #print(hypothesis)\n",
    "    #print(hypothesis)\n",
    "    return hypothesis # given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes are:  [['x' 's' 'n' ... 'k' 's' 'u']\n",
      " ['x' 's' 'y' ... 'n' 'n' 'g']\n",
      " ['b' 's' 'w' ... 'n' 'n' 'm']\n",
      " ...\n",
      " ['x' 'y' 'g' ... 'w' 'y' 'p']\n",
      " ['x' 'y' 'c' ... 'w' 'c' 'd']\n",
      " ['f' 'y' 'c' ... 'w' 'c' 'd']]\n",
      "The target is:  [1 0 0 ... 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'p',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And test your find_s function on the mushroom dataset\n",
    "attributes = np.array(data.drop(columns = 'poisonous'))\n",
    "print(\"The attributes are: \",attributes)\n",
    "\n",
    "#target variable poisonous\n",
    "target = np.array(data)[:,0] \n",
    "print(\"The target is: \",target)\n",
    "\n",
    "hypothesis = find_s(attributes, target)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**:   \n",
    "Do you notice anything about the resulting hypothesis?   \n",
    "Is FIND-S a suitable way for finding a maximally specific hypothesis in the mushroom dataset? Justify your answer.\n",
    "\n",
    "*Your solution here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Musterlösung: Since the returned hypothesis contains only one value different from '?', the FIND-S algorithm is not suitable for the mushroom dataset. This means that all mushrooms with the value 'p' of the attribute 'veil type' are classified as poisonous although they might be edible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the hypothesis you found above using the find_s function on the mushroom dataset. Save the predictions in an array.  \n",
    "If you didn't find a hypothesis use this one:\n",
    "> h_test=['?','?','?','?','?','?','?','?','?','?','?','?','?','?','?','p','?','?','?','?','?','?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = ['?','?','?','?','?','?','?','?','?','?','?','?','?','?','?','p','?','?','?','?','?','?']\n",
    "data_x = data.drop(\"poisonous\", axis=1)\n",
    "# Create Prediction with the hypothesis\n",
    "predictions = []\n",
    "for index, row in data_x.iterrows():\n",
    "    poisonous = True\n",
    "    for col in range(len(row)):\n",
    "        if hypothesis[col] == '?':\n",
    "            continue\n",
    "        if hypothesis[col] != row[col]:\n",
    "            poisonous = False\n",
    "            break\n",
    "    if poisonous:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "np.mean(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Evaluation Metrics\n",
    "Now that we know how to generate a hypothesis for concept learning, we want to be able to tell if the hypothesis is actually good or not. Therefore, we have to evaluate what prediction our hypothesis makes on a set of instances and compare these predictions to the instances' target concept.\n",
    "\n",
    "For this task, let us assume the following given set of target concepts and according predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_concept = np.loadtxt('data/target_concepts.csv').astype(int)\n",
    "predictions = np.loadtxt('data/predictions.csv').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already learned some metrics for hypotheses in the tutorial. We now want to apply these metrics to the data we just loaded. Start of by calculating the number of **True Positives (TP)**, **False Positives (FP)**, **True Negatives (TN)**, and **False Negatives (FN)**. Store the values in the given variables, you are going to use them later. Use the code given below to display the numbers in a **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0 # insert your formula here\n",
    "tn = 0 # insert your formula here\n",
    "fp = 0 # insert your formula here\n",
    "fn = 0 # insert your formula here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Musterlösung\n",
    "tp = np.logical_and(target_concept, predictions).sum()\n",
    "tn = np.logical_and(np.logical_not(target_concept), np.logical_not(predictions)).sum()\n",
    "fp = np.logical_and(np.logical_not(target_concept), predictions).sum()\n",
    "fn = np.logical_and(target_concept, np.logical_not(predictions)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "print(\"{:<19}{:^18}\".format('', 'Ground Truth'))\n",
    "print(\"{:<10}|{:^9}|{:^9}|{:^9}|\".format('', '', 'Positive', 'Negative'))\n",
    "print(\"{:<10}|{:<9}|{:^9}|{:^9}|\".format('Prediction', 'Positive', tp, fp))\n",
    "print(\"{:<10}|{:<9}|{:^9}|{:^9}|\".format('', 'Negative', fn, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the **accuracy**, using the variables from before. Use the formula you learned in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Musterlösung\n",
    "print(f\"Accuracy: {(tp + tn) / (tp+tn+fp+fn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy reduces the entire confusion matrixy to one single metric. However, this metric does not distinguish if the false predictions are false positives or false negatives. If the use case of our hypothesis requires us to make this distinction, we need other metrics. In the tutorial, you already heard about two of those metrics , namely **recall** and **precision**. Calculate both of these for the given dataset, again with the formula from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Musterlösung\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is more important -- recall or precision? That depends on how you want to use the hypothesis. Consider the following two use cases. For each of them, think about what error is more tolerable (false positives or false negatives), and thereby if recall or precision  is more important.\n",
    "\n",
    "#### Use Case 1:\n",
    "> Look at the use case from the first task. Your hypothesis is used to detect poisonous mushrooms. Imagine that those mushrooms that the hypothesis determines to be poisonous (*positive*) will be thrown away, but those that the hypothesis finds to be eatable (*negative*) will be mixed into your dinner soup.\n",
    "\n",
    "Are false positives or false negatives more tolerable? Thereby, is recall or precision more important?\n",
    "\n",
    "*Your solution here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Musterlösung: False Positives are more tolerable (If we eat only one poisonous mushroom, we probably die, but we do not really care when a few good mushrooms are thrown away). Therefore, recall is more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 2:\n",
    "> You work in a factory that manufactures products with very high quality requirements. The goal is that you must not ship a product that is flawed in any way. You are asked to build a system that supports the quality assurance process. The new process should look like this: Each manufactured product will first be evaluated by your system. If the system finds that the product fulfills all the quality standards (*positive*), it will automatically be shipped. If the system finds any flaws with the product (*negative*), it will be manually inspected by a quality specialist.\n",
    "\n",
    "Are false positives or false negatives more tolerable? Thereby, is recall or precision more important?\n",
    "\n",
    "*Your solution here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Musterlösung: False Negatives are more tolerable (If we hand an acutally good piece to manual inspection, that is no problem. If we ship a flawed product, we do not fulfill the quality requirements). Therefore, precision is more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, in many use cases we want to prevent both false negatives and false positives, so we have to consider both recall and precision. In the tutorial, you learned how to combine them into the **F1-score**. Calculate this for the dataset with the formula you learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Musterlösung\n",
    "print(f\"F1-score: {(2* precision * recall) / (precision + recall)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute, didn't we already have a metric to reduce the whole confusion matrix into one number? We did, it was the accuracy! So why do we even need the F1-score? What does it take into account that the accuracy doesn't?\n",
    "\n",
    "*Your solution here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Musterlösung!!\n",
    "> The F1-score considers both recall and precision and makes sure that they are balanced and none of them is preferred. If either recall or precision are very low, then the f1-score will be very low, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we know how to calculate some metrics for the quality of our hypothesis, and we know how to interpret them. Usually, when we evaluate a model, we do not want to bother ourselves with doing the calculations by hand. Instead, we use library functions for that.\n",
    "\n",
    "An often used library for machine learning is [scikit-learn](https://scikit-learn.org/stable/modules/classes.html). It contains easy-to-use implementations of a variety of machine learning tasks - including evaluation. You can expect to see it a few times throughout the semester, and we are going to use it for this last task.\n",
    "\n",
    "Now, calculate alle the metrics from before (confusion matrix, accuracy, recall, precision, F1-score) again, this time using the functions from `scikit-learn`. Check if the outputs match the outputs of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Musterlösung - delete this cell\n",
    "print(f\"Accuracy: {metrics.accuracy_score(target_concept, predictions)}\")\n",
    "print(f\"Confusion Matrix:\\n {metrics.confusion_matrix(target_concept, predictions)}\")\n",
    "print(f\"Recall: {metrics.recall_score(target_concept, predictions)}\")\n",
    "print(f\"Precision: {metrics.precision_score(target_concept, predictions)}\")\n",
    "print(f\"F1-Score: {metrics.f1_score(target_concept, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Embedding images\n",
    "You can embed images in a jupyter notebook on two ways: <br/>\n",
    "**First**, you can use the IPython kernel to draw an image everytime the code cell is run like shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, you can embed images directly in a Markdown cell as shown below. You can either use markdown syntax or write plain HTML code. Sometimes HTML code is more practical, as you have much finer control over the HTML elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Markdown syntax:\n",
    "```\n",
    "![title](images/logo.png)\n",
    "```\n",
    "2. HTML syntax\n",
    "```\n",
    "<img src=\"images/logo.png\" style=\"width: 70px;\"/>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
